{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Inject\n",
    "\n",
    "Implementation of feature inject ([paper](https://arxiv.org/abs/2501.14524)) using hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T11:13:31.008400Z",
     "iopub.status.busy": "2025-11-05T11:13:31.008134Z",
     "iopub.status.idle": "2025-11-05T11:14:57.043543Z",
     "shell.execute_reply": "2025-11-05T11:14:57.042863Z",
     "shell.execute_reply.started": "2025-11-05T11:13:31.008379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "from main import main\n",
    "import yaml\n",
    "import gc\n",
    "\n",
    "# Determine device.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "\n",
    "model = \"stabilityai/sd-turbo\" #\"CompVis/stable-diffusion-v1-4\" \n",
    "variant = 'fp16'\n",
    "model_name ='auto'\n",
    "image_size = 512 \n",
    "float_ = torch.float16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_test import generate_triplet\n",
    "output_folder = 'outputs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "selected_skip_keys = [\n",
    "        ['unet.up_blocks.0.resnets.0'],\n",
    "        ['unet.up_blocks.0.resnets.1'],\n",
    "        ['unet.up_blocks.0.resnets.2'],\n",
    "        ['unet.up_blocks.1.resnets.0'],\n",
    "        ['unet.up_blocks.0.resnets.0',\n",
    "        'unet.up_blocks.1.resnets.0'],\n",
    "        ['unet.up_blocks.0.resnets.0',\n",
    "        'unet.up_blocks.0.resnets.1',\n",
    "        'unet.up_blocks.0.resnets.2'],\n",
    "        ['unet.up_blocks.0.resnets.0',\n",
    "        'unet.up_blocks.0.resnets.1',\n",
    "        'unet.up_blocks.0.resnets.2',\n",
    "        'unet.up_blocks.1.resnets.0']]\n",
    "\n",
    "\n",
    "\n",
    "generate_triplet(\n",
    "    source_prompt=\"a dog on a chair\",\n",
    "    target_prompt=\"a cat on a chair\",\n",
    "    output_folder=\"outputs/triplet_test\",\n",
    "    model=model,\n",
    "    model_name=model_name,\n",
    "    variant=variant,\n",
    "    device=device,\n",
    "    image_size=image_size,\n",
    "    selected_skip_keys=selected_skip_keys,\n",
    "    float_=float_,\n",
    "    main_fn=main  # your generation function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "execution": {
     "execution_failed": "2025-11-03T13:56:53.270Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running test #1 ---\n",
      "scale=0.0, seed=50, ddim_steps=3\n",
      "source_prompt='a photo of a horse in mud'\n",
      "target_prompts=['a photo of a zebra in the snow', 'a photo of a husky on the grass', 'an oil painting of a white horse', 'a photo of a blue horse toy in playroom']\n",
      "Generating A & B for a photo of a horse in mud -> a photo of a zebra in the snow\n",
      "\n",
      "Initializing Pipeline A (skip capture mode)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00,  8.93it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "args = {}\n",
    "\n",
    "output_folder = 'outputs_eval'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "selected_skip_keys = [\n",
    "        ['unet.up_blocks.0.resnets.0'],\n",
    "        ['unet.up_blocks.0.resnets.1'],\n",
    "        ['unet.up_blocks.0.resnets.2'],\n",
    "        ['unet.up_blocks.1.resnets.0'],\n",
    "        ['unet.up_blocks.0.resnets.0',\n",
    "        'unet.up_blocks.1.resnets.0'],\n",
    "        ['unet.up_blocks.0.resnets.0',\n",
    "        'unet.up_blocks.0.resnets.1',\n",
    "        'unet.up_blocks.0.resnets.2'],\n",
    "        ['unet.up_blocks.0.resnets.0',\n",
    "        'unet.up_blocks.0.resnets.1',\n",
    "        'unet.up_blocks.0.resnets.2',\n",
    "        'unet.up_blocks.1.resnets.0']]\n",
    "\n",
    "\n",
    "yml_file = 'data/pnp/wild-ti2i-fake.yaml'\n",
    "\n",
    "with open(yml_file, \"r\") as f:\n",
    "    tests = yaml.safe_load(f)  # This should be a list of dicts (each dict is one test)\n",
    "\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for idx, test in enumerate(tests):\n",
    "    scale = test.get(\"scale\", 7.5)\n",
    "    seed = test.get(\"seed\", 0)\n",
    "    ddim_steps = test.get(\"ddim_steps\", 50)\n",
    "    source_prompt = test.get(\"source_prompt\", \"\")\n",
    "    target_prompts = test.get(\"target_prompts\", [])\n",
    "        \n",
    "    if 'turbo' in model or 'schnell' in model:\n",
    "        scale = 0.0\n",
    "        ddim_steps = 3\n",
    "\n",
    "    if 'kandinsky' in model:\n",
    "        ddim_steps = min(ddim_steps, 30)\n",
    "        \n",
    "    print(f\"\\n--- Running test #{idx+1} ---\")\n",
    "    print(f\"scale={scale}, seed={seed}, ddim_steps={ddim_steps}\")\n",
    "    print(f\"source_prompt='{source_prompt}'\")\n",
    "    print(f\"target_prompts={target_prompts}\")\n",
    "    \n",
    "    for j, target_prompt in enumerate(target_prompts):\n",
    "        test_tag = f\"test{idx+1}_pair{j+1}\"\n",
    "\n",
    "        # ---- Generate A & B once ----\n",
    "        base_args = {\n",
    "            'out_dir': output_folder,\n",
    "            'prompt_A': target_prompt,\n",
    "            'variant': variant,\n",
    "            'device': device,\n",
    "            'prompt_B': source_prompt,\n",
    "            'image_size': image_size,\n",
    "            'model': model,\n",
    "            'model_name': model_name,\n",
    "            'guidance_scale': 0.0 if ('turbo' in model) or ('schnell' in model) else scale,\n",
    "            'num_inference_steps': args.get('num_inference_steps', ddim_steps),\n",
    "            'seed': seed,\n",
    "            'float': float_,\n",
    "            'timesteps': [1000, 0],\n",
    "            'switch_guidance': {},\n",
    "            'selected_skip_keys': selected_skip_keys[0]\n",
    "        }\n",
    "\n",
    "        print(f\"Generating A & B for {source_prompt} -> {target_prompt}\")\n",
    "        image_A, image_B, injected_skips, pipe_B = main(Namespace(**base_args), save_results=False, save_b=True)\n",
    "        image_A.save(os.path.join(output_folder, f\"A_{test_tag}.png\"))\n",
    "        image_B.save(os.path.join(output_folder, f\"B_{test_tag}.png\"))\n",
    "\n",
    "        # ---- Loop over hyperparameters for C ----\n",
    "        switch_guidance_list = [{}]#, 0.9, 1.2]\n",
    "        timestep_list = [[1000, 200]]#, [1000, 100], [1000,200]]\n",
    "\n",
    "        for skips in selected_skip_keys:\n",
    "            print(skips)\n",
    "            skip_tag = f\"skips_{'_'.join([s.split('.')[-1] +'_' + s.split('.')[-3] for s in skips])}\"\n",
    "\n",
    "            for sg, ts in zip(switch_guidance_list, timestep_list):\n",
    "                hyper_args = base_args.copy()\n",
    "                hyper_args.update({\n",
    "                    'switch_guidance': sg,\n",
    "                    'timesteps': ts,\n",
    "                    'selected_skip_keys': skips\n",
    "                })\n",
    "\n",
    "                print(f\"Generating C with skip={skip_tag}, SG={sg}, timesteps={ts}\")\n",
    "                image_C = main(Namespace(**hyper_args), injected_skips=injected_skips, pipe_B=pipe_B, save_results=False)\n",
    "    \n",
    "                # Save C with detailed name\n",
    "                sg_tag = f\"SG{sg}_T{ts[0]}-{ts[1]}\"\n",
    "                filename = f\"C_{test_tag}_{skip_tag}_{sg_tag}.png\"\n",
    "                image_C.save(os.path.join(output_folder, filename))\n",
    "                \n",
    "                # Save metadata\n",
    "                metadata = {\n",
    "                    \"test_pair\": test_tag,\n",
    "                    \"source_prompt\": source_prompt,\n",
    "                    \"target_prompt\": target_prompt,\n",
    "                    \"scale\": scale,\n",
    "                    \"seed\": seed,\n",
    "                    \"ddim_steps\": ddim_steps,\n",
    "                    \"skip_injection\": skips,\n",
    "                    \"switch_guidance\": sg,\n",
    "                    \"timesteps\": ts\n",
    "                }\n",
    "                meta_name = f\"metadata_{test_tag}_{skip_tag}_{sg_tag}.json\"\n",
    "                with open(os.path.join(output_folder, meta_name), \"w\") as f:\n",
    "                    json.dump(metadata, f, indent=4)\n",
    "        del pipe_B\n",
    "        gc.collect()\n",
    "\n",
    "        #time.sleep(5)\n",
    "\n",
    "    # Save general config for this test\n",
    "    config = {\n",
    "        \"scale\": scale,\n",
    "        \"seed\": seed,\n",
    "        \"ddim_steps\": ddim_steps,\n",
    "        \"model\": model,\n",
    "        \"selected_skip_keys\": selected_skip_keys\n",
    "    }\n",
    "    config_path = os.path.join(output_folder, \"config.json\")\n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    print(f\"Saved experiment config to {config_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T11:14:57.045673Z",
     "iopub.status.busy": "2025-11-05T11:14:57.045128Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating A & B for A high-resolution image of a steampunk airship in the old european village, cyberpunk aesthetic -> A high-resolution image of a vintage camera in the coral reef underwater world, japanese anime style\n",
      "\n",
      "Initializing Pipeline A (skip capture mode)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00, 11.75it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 52 blocks for injection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Pipeline C (non-injected mode)...\n",
      "Saved 52 blocks for injection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.67s/it]\n",
      "Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00,  8.85it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating C with skip=skips_unet.down_blocks.0.resnets.0\n",
      "\n",
      "Initializing Pipeline A (skip capture mode)...\n",
      "Saved 52 blocks for injection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating C with skip=skips_unet.down_blocks.0.attentions.0\n",
      "\n",
      "Initializing Pipeline A (skip capture mode)...\n",
      "Saved 52 blocks for injection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating C with skip=skips_unet.down_blocks.0.resnets.1\n",
      "\n",
      "Initializing Pipeline A (skip capture mode)...\n",
      "Saved 52 blocks for injection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating C with skip=skips_unet.down_blocks.0.attentions.1\n",
      "\n",
      "Initializing Pipeline A (skip capture mode)...\n",
      "Saved 52 blocks for injection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating C with skip=skips_unet.down_blocks.1.resnets.0\n",
      "\n",
      "Initializing Pipeline A (skip capture mode)...\n",
      "Saved 52 blocks for injection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating C with skip=skips_unet.down_blocks.1.attentions.0\n",
      "\n",
      "Initializing Pipeline A (skip capture mode)...\n",
      "Saved 52 blocks for injection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:07<00:02,  2.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     71\u001b[39m hyper_args.update({\n\u001b[32m     72\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mselected_skip_keys\u001b[39m\u001b[33m'\u001b[39m: sample\n\u001b[32m     73\u001b[39m })\n\u001b[32m     74\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating C with skip=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskip_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m image_C = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNamespace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhyper_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minjected_skips\u001b[49m\u001b[43m=\u001b[49m\u001b[43minjected_skips\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe_B\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipe_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_results\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskip_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m image_C.save(os.path.join(output_folder, sg_tag, filename))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/feature-inject/main.py:86\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(args, injected_skips, pipe_B, save_results, save_b)\u001b[39m\n\u001b[32m     77\u001b[39m pipe_B, hook_handles = register_skip_hooks(\n\u001b[32m     78\u001b[39m         pipe_B,\n\u001b[32m     79\u001b[39m         injected_skips,\n\u001b[32m   (...)\u001b[39m\u001b[32m     83\u001b[39m         args.timesteps,\n\u001b[32m     84\u001b[39m )\n\u001b[32m     85\u001b[39m generator = torch.Generator(device).manual_seed(args.seed)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m final_output_B, _ = \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpipe_B\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprompt_B\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m final_image_b = final_output_B.images[\u001b[32m0\u001b[39m]\n\u001b[32m     95\u001b[39m remove_skip_hooks(hook_handles)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/feature-inject/utils/utils_test.py:86\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(pipe, prompt, num_inference_steps, image_size, generator, guidance_scale)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_pipeline\u001b[39m(pipe, prompt: \u001b[38;5;28mstr\u001b[39m, num_inference_steps: \u001b[38;5;28mint\u001b[39m, image_size: \u001b[38;5;28mint\u001b[39m, generator, guidance_scale: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[32m     72\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m    Run inference with the given diffusion pipeline.\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m \u001b[33;03m        A tuple (final_output, skip_connections) where final_output typically includes the generated image.\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/feature-inject/src/hooked_sd_pipeline.py:310\u001b[39m, in \u001b[36mModifiedStableDiffusionPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    306\u001b[39m                 blocks_to_save.append(\u001b[33m'\u001b[39m\u001b[33mtransformer.\u001b[39m\u001b[33m'\u001b[39m + name)\n\u001b[32m    308\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSaved\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(blocks_to_save), \u001b[33m'\u001b[39m\u001b[33mblocks for injection.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m final_output, cache_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpositions_to_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocks_to_save\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;66;03m# The cache dictionary is organized as: {'output': {position: tensor_list, ...}}.\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# Here we simply extract the cached skip activations.\u001b[39;00m\n\u001b[32m    320\u001b[39m skip_connections = cache_dict.get(\u001b[33m'\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m'\u001b[39m, {})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/feature-inject/src/hooked_sd_pipeline.py:64\u001b[39m, in \u001b[36mHookedDiffusionAbstractPipeline.run_with_cache\u001b[39m\u001b[34m(self, positions_to_cache, save_input, save_output, *args, **kwargs)\u001b[39m\n\u001b[32m     60\u001b[39m hooks = [\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m._register_cache_hook(position, cache_input, cache_output) \u001b[38;5;28;01mfor\u001b[39;00m position \u001b[38;5;129;01min\u001b[39;00m positions_to_cache\n\u001b[32m     62\u001b[39m ]\n\u001b[32m     63\u001b[39m hooks = [hook \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks \u001b[38;5;28;01mif\u001b[39;00m hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks:\n\u001b[32m     66\u001b[39m     hook.remove()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:1041\u001b[39m, in \u001b[36mStableDiffusionPipeline.__call__\u001b[39m\u001b[34m(self, prompt, height, width, num_inference_steps, timesteps, sigmas, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[39m\n\u001b[32m   1038\u001b[39m     latent_model_input = \u001b[38;5;28mself\u001b[39m.scheduler.scale_model_input(latent_model_input, t)\n\u001b[32m   1040\u001b[39m \u001b[38;5;66;03m# predict the noise residual\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m noise_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimestep_cond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimestep_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m   1051\u001b[39m \u001b[38;5;66;03m# perform guidance\u001b[39;00m\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_classifier_free_guidance:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/diffusers/models/unets/unet_2d_condition.py:1280\u001b[39m, in \u001b[36mUNet2DConditionModel.forward\u001b[39m\u001b[34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[39m\n\u001b[32m   1277\u001b[39m     upsample_size = down_block_res_samples[-\u001b[32m1\u001b[39m].shape[\u001b[32m2\u001b[39m:]\n\u001b[32m   1279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(upsample_block, \u001b[33m\"\u001b[39m\u001b[33mhas_cross_attention\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m upsample_block.has_cross_attention:\n\u001b[32m-> \u001b[39m\u001b[32m1280\u001b[39m     sample = \u001b[43mupsample_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemb\u001b[49m\u001b[43m=\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mres_hidden_states_tuple\u001b[49m\u001b[43m=\u001b[49m\u001b[43mres_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mupsample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1289\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1290\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1291\u001b[39m     sample = upsample_block(\n\u001b[32m   1292\u001b[39m         hidden_states=sample,\n\u001b[32m   1293\u001b[39m         temb=emb,\n\u001b[32m   1294\u001b[39m         res_hidden_states_tuple=res_samples,\n\u001b[32m   1295\u001b[39m         upsample_size=upsample_size,\n\u001b[32m   1296\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/diffusers/models/unets/unet_2d_blocks.py:2469\u001b[39m, in \u001b[36mCrossAttnUpBlock2D.forward\u001b[39m\u001b[34m(self, hidden_states, res_hidden_states_tuple, temb, encoder_hidden_states, cross_attention_kwargs, upsample_size, attention_mask, encoder_attention_mask)\u001b[39m\n\u001b[32m   2467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.upsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2468\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.upsamplers:\n\u001b[32m-> \u001b[39m\u001b[32m2469\u001b[39m         hidden_states = \u001b[43mupsampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsample_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/diffusers/models/upsampling.py:177\u001b[39m, in \u001b[36mUpsample2D.forward\u001b[39m\u001b[34m(self, hidden_states, output_size, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m     hidden_states = hidden_states.contiguous()\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     hidden_states = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnearest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    179\u001b[39m     hidden_states = F.interpolate(hidden_states, size=output_size, mode=\u001b[33m\"\u001b[39m\u001b[33mnearest\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/torch/nn/functional.py:4649\u001b[39m, in \u001b[36minterpolate\u001b[39m\u001b[34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[39m\n\u001b[32m   4647\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._nn.upsample_nearest1d(\u001b[38;5;28minput\u001b[39m, output_size, scale_factors)\n\u001b[32m   4648\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.dim() == \u001b[32m4\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mnearest\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4649\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsample_nearest2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.dim() == \u001b[32m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mnearest\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   4651\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._nn.upsample_nearest3d(\u001b[38;5;28minput\u001b[39m, output_size, scale_factors)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import random \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "import sys\n",
    "sys.path.insert(0, './test')\n",
    "from prompts import scribblr_prompts, stockimg_prompts, objects, backgrounds, styles\n",
    "    \n",
    "test_type = 'controlled'\n",
    "\n",
    "output_folder = 'outputs_test_2turbo_new_'+test_type\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "if test_type == 'wild':\n",
    "    prompts = scribblr_prompts + stockimg_prompts\n",
    "\n",
    "    # sample a list of 500 random combinations of prompts (no duplicates)\n",
    "    sampled_prompts = random.sample([(a, b) for a in prompts for b in prompts if a != b], 10)         \n",
    "    print(sampled_prompts)\n",
    "else:\n",
    "    sampled_prompts = []\n",
    "    # sample combinations of object, background, style 500 times\n",
    "    for i in range(500): \n",
    "        obj = random.choice(objects)\n",
    "        back = random.choice(backgrounds)\n",
    "        style = random.choice(styles)\n",
    "        prompt1 = f\"A high-resolution image of a {obj} in the {back}, {style}\"\n",
    "        \n",
    "        obj_2 = random.choice(objects)\n",
    "        back_2 = random.choice(backgrounds)\n",
    "        style_2 = random.choice(styles)\n",
    "        prompt2 = f\"A high-resolution image of a {obj_2} in the {back_2}, {style_2}\"\n",
    "        \n",
    "        if prompt1 != prompt2 and (prompt1, prompt2) not in sampled_prompts:\n",
    "            sampled_prompts.append((prompt1, prompt2))\n",
    "                \n",
    "                        \n",
    "scale = 0.0\n",
    "seed = 42\n",
    "ddim_steps = 4\n",
    "\n",
    "# Generate all commands.\n",
    "for prompt_A, prompt_B in sampled_prompts:\n",
    "    sg_tag = f\"{'_'.join(prompt_A.split())}_{'_'.join(prompt_B.split())}\"\n",
    "    if not os.path.isdir(os.path.join(output_folder, sg_tag)):\n",
    "        os.makedirs(os.path.join(output_folder, sg_tag), exist_ok=True)\n",
    "        print(f\"Generating A & B for {prompt_A} -> {prompt_B}\")\n",
    "        base_args = {\n",
    "            'out_dir': output_folder,\n",
    "            'prompt_A': prompt_A,\n",
    "            'variant': variant,\n",
    "            'device': device,\n",
    "            'prompt_B': prompt_B,\n",
    "            'image_size': image_size,\n",
    "            'model': model,\n",
    "            'model_name': model_name,\n",
    "            'guidance_scale': 0.0 if ('turbo' in model) or ('schnell' in model) else scale,\n",
    "            'num_inference_steps': ddim_steps,\n",
    "            'seed': seed,\n",
    "            'float': float_,\n",
    "            'timesteps': [1000, 0],\n",
    "            'switch_guidance': {},\n",
    "            'selected_skip_keys': ''\n",
    "        }\n",
    "        image_A, image_B, injected_skips, pipe_B = main(Namespace(**base_args), save_results=False, save_b=True)\n",
    "        image_A.save(os.path.join(output_folder, sg_tag, f\"A.png\"))\n",
    "        image_B.save(os.path.join(output_folder, sg_tag, f\"B.png\"))\n",
    "        for layer in injected_skips.keys():\n",
    "            sample = [layer]\n",
    "            skip_tag = f\"skips_{'_'.join(sample)}\"\n",
    "             \n",
    "            hyper_args = base_args.copy()\n",
    "            hyper_args.update({\n",
    "                    'selected_skip_keys': sample\n",
    "            })\n",
    "            print(f\"Generating C with skip={skip_tag}\")\n",
    "            image_C = main(Namespace(**hyper_args), injected_skips=injected_skips, pipe_B=pipe_B, save_results=False)\n",
    "            filename = f\"C_{skip_tag}.png\"\n",
    "            image_C.save(os.path.join(output_folder, sg_tag, filename))\n",
    "        \n",
    "        for i in range(15):\n",
    "            n = random.choice([2, 3])\n",
    "            sample = random.sample(list(injected_skips.keys()), n)\n",
    "            skip_tag = f\"skips_{'_'.join(sample)}\"\n",
    "             \n",
    "            hyper_args = base_args.copy()\n",
    "            hyper_args.update({\n",
    "                    'selected_skip_keys': sample\n",
    "            })\n",
    "            print(f\"Generating C with skip={skip_tag}\")\n",
    "            image_C = main(Namespace(**hyper_args), injected_skips=injected_skips, pipe_B=pipe_B, save_results=False)\n",
    "            filename = f\"C_{skip_tag}.png\"\n",
    "            image_C.save(os.path.join(output_folder, sg_tag, filename))\n",
    "        del pipe_B\n",
    "        gc.collect()\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheaf_arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
