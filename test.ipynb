{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip Inject\n",
    "\n",
    "Implementation of skip inject ([paper](https://arxiv.org/abs/2501.14524)) using hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T22:40:41.061927Z",
     "iopub.status.busy": "2025-09-24T22:40:41.061338Z",
     "iopub.status.idle": "2025-09-24T22:40:51.198281Z",
     "shell.execute_reply": "2025-09-24T22:40:51.197816Z",
     "shell.execute_reply.started": "2025-09-24T22:40:41.061910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ludovicaschaerf/miniforge3/envs/sheaf_arm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "from test import main\n",
    "import yaml\n",
    "import gc\n",
    "\n",
    "# Determine device.\n",
    "device = 'mps'\n",
    "\n",
    "model = \"stabilityai/sd-turbo\" \n",
    "variant = 'fp16'\n",
    "model_name ='auto'\n",
    "image_size = 512 \n",
    "float_ = torch.float16\n",
    "\n",
    "model = \"stabilityai/stable-diffusion-3.5-large-turbo\" #\n",
    "model_name ='sd3'\n",
    "image_size = 1024 \n",
    "\n",
    "yml_file = 'data/pnp/wild-style-fake.yaml'\n",
    "output_folder = 'outputs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-09-24T22:40:51.250150Z",
     "iopub.status.busy": "2025-09-24T22:40:51.249563Z",
     "iopub.status.idle": "2025-09-24T22:45:23.960651Z",
     "shell.execute_reply": "2025-09-24T22:45:23.960273Z",
     "shell.execute_reply.started": "2025-09-24T22:40:51.250134Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running test #1 ---\n",
      "scale=0.0, seed=50, ddim_steps=3\n",
      "source_prompt='a photo of a horse in mud'\n",
      "target_prompts=['An Renaissance painting image', 'An Cubism image', 'An Surrealism image', 'An Pop Art image']\n",
      "Generating A & B for a photo of a horse in mud -> An Renaissance painting image\n",
      "\n",
      "Initializing Pipeline A (skip capture mode)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A mixture of fp16 and non-fp16 filenames will be loaded.\n",
      "Loaded fp16 filenames:\n",
      "[text_encoder_2/model.fp16.safetensors, text_encoder/model.fp16.safetensors, text_encoder_3/model.fp16-00002-of-00002.safetensors, text_encoder_3/model.fp16-00001-of-00002.safetensors, text_encoder_3/model.safetensors.index.fp16.json]\n",
      "Loaded non-fp16 filenames:\n",
      "[transformer/diffusion_pytorch_model-00001-of-00002.safetensors, transformer/diffusion_pytorch_model-00002-of-00002.safetensors, transformer/diffusion_pytorch_model.safetensors.index.json, vae/diffusion_pytorch_model.safetensors\n",
      "If this behavior is not expected, please check your folder structure.\n",
      "Fetching 28 files:   7%|â–‹         | 2/28 [00:00<00:04,  6.25it/s]"
     ]
    }
   ],
   "source": [
    "args = {}\n",
    "\n",
    "with open(yml_file, \"r\") as f:\n",
    "    tests = yaml.safe_load(f)  # This should be a list of dicts (each dict is one test)\n",
    "\n",
    "selected_skip_keys = [\n",
    "        ['unet.up_blocks.1.resnets.0'],\n",
    "        ['unet.up_blocks.1.resnets.1'],\n",
    "        ['unet.up_blocks.1.resnets.0',\n",
    "        'unet.up_blocks.1.attentions.0'],\n",
    "        ['unet.up_blocks.1.resnets.0',\n",
    "        'unet.up_blocks.1.resnets.1',]]\n",
    "\n",
    "selected_skip_keys = [['transformer.transformer_blocks.22', \n",
    "                       'transformer.transformer_blocks.23'],\n",
    "                      ['transformer.transformer_blocks.23'],\n",
    "                      ['transformer.transformer_blocks.22']\n",
    "                     ]                 \n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for idx, test in enumerate(tests):\n",
    "    scale = test.get(\"scale\", 7.5)\n",
    "    seed = test.get(\"seed\", 0)\n",
    "    ddim_steps = test.get(\"ddim_steps\", 50)\n",
    "    source_prompt = test.get(\"source_prompt\", \"\")\n",
    "    target_prompts = test.get(\"target_prompts\", [])\n",
    "        \n",
    "    if 'turbo' in model or 'schnell' in model:\n",
    "        scale = 0.0\n",
    "        ddim_steps = 3\n",
    "\n",
    "    if 'kandinsky' in model:\n",
    "        ddim_steps = min(ddim_steps, 30)\n",
    "        \n",
    "    print(f\"\\n--- Running test #{idx+1} ---\")\n",
    "    print(f\"scale={scale}, seed={seed}, ddim_steps={ddim_steps}\")\n",
    "    print(f\"source_prompt='{source_prompt}'\")\n",
    "    print(f\"target_prompts={target_prompts}\")\n",
    "    \n",
    "    for j, target_prompt in enumerate(target_prompts):\n",
    "        test_tag = f\"test{idx+1}_pair{j+1}\"\n",
    "\n",
    "        # ---- Generate A & B once ----\n",
    "        base_args = {\n",
    "            'out_dir': output_folder,\n",
    "            'prompt_A': target_prompt,\n",
    "            'variant': variant,\n",
    "            'device': device,\n",
    "            'prompt_B': source_prompt,\n",
    "            'image_size': image_size,\n",
    "            'model': model,\n",
    "            'model_name': model_name,\n",
    "            'guidance_scale': 0.0 if ('turbo' in model) or ('schnell' in model) else scale,\n",
    "            'num_inference_steps': args.get('num_inference_steps', ddim_steps),\n",
    "            'seed': seed,\n",
    "            'float': float_,\n",
    "            'timesteps': [1000, 0],\n",
    "            'switch_guidance': {},\n",
    "            'selected_skip_keys': selected_skip_keys[0]\n",
    "        }\n",
    "\n",
    "        print(f\"Generating A & B for {source_prompt} -> {target_prompt}\")\n",
    "        image_A, image_B, injected_skips, pipe_B = main(Namespace(**base_args), save_results=False, save_b=True)\n",
    "        image_A.save(os.path.join(output_folder, f\"A_{test_tag}.png\"))\n",
    "        image_B.save(os.path.join(output_folder, f\"B_{test_tag}.png\"))\n",
    "\n",
    "        # ---- Loop over hyperparameters for C ----\n",
    "        switch_guidance_list = [{}]#, 0.9, 1.2]\n",
    "        timestep_list = [[1000, 200]]#, [1000, 100], [1000,200]]\n",
    "\n",
    "        for skips in selected_skip_keys:\n",
    "            print(skips)\n",
    "            skip_tag = f\"skips_{'_'.join([s.split('.')[-1] +'_' + s.split('.')[-3] for s in skips])}\"\n",
    "\n",
    "            for sg, ts in zip(switch_guidance_list, timestep_list):\n",
    "                hyper_args = base_args.copy()\n",
    "                hyper_args.update({\n",
    "                    'switch_guidance': sg,\n",
    "                    'timesteps': ts,\n",
    "                    'selected_skip_keys': skips\n",
    "                })\n",
    "\n",
    "                print(f\"Generating C with skip={skip_tag}, SG={sg}, timesteps={ts}\")\n",
    "                image_C = main(Namespace(**hyper_args), injected_skips=injected_skips, pipe_B=pipe_B, save_results=False)\n",
    "    \n",
    "                # Save C with detailed name\n",
    "                sg_tag = f\"SG{sg}_T{ts[0]}-{ts[1]}\"\n",
    "                filename = f\"C_{test_tag}_{skip_tag}_{sg_tag}.png\"\n",
    "                image_C.save(os.path.join(output_folder, filename))\n",
    "                \n",
    "                # Save metadata\n",
    "                metadata = {\n",
    "                    \"test_pair\": test_tag,\n",
    "                    \"source_prompt\": source_prompt,\n",
    "                    \"target_prompt\": target_prompt,\n",
    "                    \"scale\": scale,\n",
    "                    \"seed\": seed,\n",
    "                    \"ddim_steps\": ddim_steps,\n",
    "                    \"skip_injection\": skips,\n",
    "                    \"switch_guidance\": sg,\n",
    "                    \"timesteps\": ts\n",
    "                }\n",
    "                meta_name = f\"metadata_{test_tag}_{skip_tag}_{sg_tag}.json\"\n",
    "                with open(os.path.join(output_folder, meta_name), \"w\") as f:\n",
    "                    json.dump(metadata, f, indent=4)\n",
    "        del pipe_B\n",
    "        gc.collect()\n",
    "\n",
    "        #time.sleep(5)\n",
    "\n",
    "    # Save general config for this test\n",
    "    config = {\n",
    "        \"scale\": scale,\n",
    "        \"seed\": seed,\n",
    "        \"ddim_steps\": ddim_steps,\n",
    "        \"model\": model,\n",
    "        \"selected_skip_keys\": selected_skip_keys\n",
    "    }\n",
    "    config_path = os.path.join(output_folder, \"config.json\")\n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    print(f\"Saved experiment config to {config_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheaf_arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
